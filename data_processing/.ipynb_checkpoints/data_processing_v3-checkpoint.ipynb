{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Req'd Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all the file_names in a given directory\n",
    "def get_file_names(folder):\n",
    "    #Listing entries present in given folder\n",
    "    entries = os.listdir(folder)\n",
    "    for i in entries:\n",
    "        if 'csv' not in i:\n",
    "            entries.remove(i)\n",
    "    return sorted(entries, reverse=True)\n",
    "\n",
    "#Saving the file\n",
    "def save_file(root, name_of_file, my_dataframe):\n",
    "    #Test if save directory exists\n",
    "    try:\n",
    "        my_dataframe.to_csv(root+'processed_data/'+ name_of_file, index=False)\n",
    "    #Otherwise make the directory and then save\n",
    "    except:\n",
    "        os.mkdir(root+'processed_data')\n",
    "        my_dataframe.to_csv(root+'processed_data/'+ name_of_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(filepath):\n",
    "    df = pd.read_csv(filepath, \n",
    "                     usecols = ['id','last_scraped', 'host_is_superhost', \n",
    "                            'latitude','longitude', 'property_type',\n",
    "                           'room_type','accommodates','bathrooms',\n",
    "                           'bedrooms','beds','amenities', 'price',\n",
    "                            'instant_bookable','cancellation_policy'])\n",
    "    df[\"last_scraped\"] = pd.to_datetime(df[\"last_scraped\"])\n",
    "    df[\"price\"] = df[\"price\"].apply(lambda x: x.replace('$','').replace(',', '').replace('.00', '')).astype(\"int\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating All Data Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of filenames\n",
    "root = '../'\n",
    "name = get_file_names(root+'original_dataset')\n",
    "accum_kept = 0\n",
    "accum_removed = 0\n",
    "\n",
    "# combine all files into one\n",
    "print(\"COMBINING INTO ONE DATAFRAME...\")\n",
    "frames = []\n",
    "for i in name:\n",
    "    print(\"--Processing: \", i)\n",
    "    filepath = root+'original_dataset/'+i\n",
    "    frames.append(initialization(filepath))\n",
    "full_df = pd.concat(frames, sort=False)\n",
    "\n",
    "initial_samples = len(full_df)\n",
    "print(\"Initial # of Samples: \", len(full_df))\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "# Drop missing values\n",
    "print(\"DELETING SAMPLES WITH MISSING VALUES...\")\n",
    "full_df = full_df.dropna()\n",
    "samples1 = len(full_df)\n",
    "print(\"--Number of Samples Removed: \", initial_samples-samples1)\n",
    "\n",
    "# reset index\n",
    "full_df = full_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numericalize Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping for Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellation_policies = {\n",
    "    \"flexible\": 1,\n",
    "    \"moderate\": 5,\n",
    "    \"strict_14_with_grace_period\": 14,\n",
    "    \"super_strict_30\": 30,\n",
    "    \"super_strict_60\": 60\n",
    "}\n",
    "room_types = {\n",
    "    \"Entire home/apt\": 0,\n",
    "    \"Private room\": 1,\n",
    "    \"Shared room\": 2\n",
    "}\n",
    "true_false = {\n",
    "    't': 1,\n",
    "    'f': 0,\n",
    "    True: 1,\n",
    "    False: 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert t/f into 1/0\n",
    "print(\"NUMERICALIZING TRUE/FALSE...\")\n",
    "for i in [\"host_is_superhost\", \"instant_bookable\"]:\n",
    "    full_df[i] = full_df[i].map(true_false)\n",
    "    print(full_df[i].value_counts())\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "# cancellation policy\n",
    "print(\"NUMERICALIZING CANCELLATION POLICY...\")\n",
    "print(full_df[\"cancellation_policy\"].value_counts())\n",
    "full_df[\"cancellation_policy\"] = full_df[\"cancellation_policy\"].map(cancellation_policies)\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "# room_type\n",
    "print(\"NUMERICALIZING ROOM TYPE...\")\n",
    "print(full_df[\"room_type\"].value_counts())\n",
    "full_df[\"room_type\"] = full_df[\"room_type\"].map(room_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping for Property Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_types = {\n",
    "    \"House\" : 1,\n",
    "    \"Apartment\" : 2,\n",
    "    \"Condominium\" : 5,\n",
    "    \"Townhouse\" : 3,\n",
    "    \"Bungalow\" : 0,\n",
    "    \"Loft\" : 4,\n",
    "    \"Serviced Apartment\" : 6,\n",
    "    \"Guest Suite\" : 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FILTERLING AND NUMERICALIZING PROPERTY TYPES...\")\n",
    "property_type_counts = full_df[\"property_type\"].value_counts()\n",
    "accum = []\n",
    "for i in range(len(property_type_counts)):\n",
    "    if property_type_counts[i] >= 0.01*samples1:\n",
    "        accum.append(property_type_counts.index[i])\n",
    "print(\"Types of Included Properties:\")\n",
    "print(accum)\n",
    "\n",
    "full_df = full_df[full_df[\"property_type\"].isin(accum)]\n",
    "print(full_df[\"property_type\"].value_counts())\n",
    "\n",
    "full_df[\"property_type\"] = full_df[\"property_type\"].map(property_types)\n",
    "\n",
    "samples2 = len(full_df)\n",
    "print(\"Number of Samples Removed:\", samples1 - samples2)\n",
    "full_df = full_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Mean and Std Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std = pd.DataFrame(columns = [\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(BEFORE) PRICE STATISTICS...\")\n",
    "print(full_df[\"price\"].describe())\n",
    "print(full_df[\"price\"].quantile([0.01, 0.05, 0.1, 0.9, 0.95, 0.99]))\n",
    "\n",
    "print(\"\")\n",
    "print(\"TRIMMING PRICE OUTLIERS...\")\n",
    "min_price = full_df[\"price\"].quantile(0.05)\n",
    "max_price = full_df[\"price\"].quantile(0.95)\n",
    "\n",
    "full_df = full_df[(full_df[\"price\"] >= min_price) & (full_df[\"price\"] <= max_price)]\n",
    "samples3 = len(full_df)\n",
    "print(\"--Number of Samples Removed: \", samples2-samples3)\n",
    "full_df = full_df.reset_index(drop=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"STANDARDIZING PRICE...\") # using Z-score\n",
    "mean_price = full_df[\"price\"].mean()\n",
    "std_price = full_df[\"price\"].std()\n",
    "full_df[\"price\"] = (full_df[\"price\"] - mean_price)/std_price\n",
    "print(\"--Mean Price: \", mean_price)\n",
    "print(\"--Std Price: \", std_price)\n",
    "temp = pd.DataFrame([[mean_price, std_price]], columns=[\"mean\", \"std\"], index=[\"price\"])\n",
    "mean_std = mean_std.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorizing Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities = ['Kitchen', 'Heating', 'Washer', 'Wifi', 'Indoor fireplace', 'Iron', \n",
    "             'Laptop friendly workspace', 'Crib', 'Self check-in', 'Carbon monoxide detector', \n",
    "             'Shampoo', 'Air conditioning', 'Dryer', 'Breakfast', 'Hangers', 'Hair dryer', \n",
    "             'TV', 'High chair', 'Smoke detector', 'Private bathroom']\n",
    "\n",
    "facilities = ['Free parking on premises', 'Gym', 'Hot tub', 'Pool']\n",
    "\n",
    "house_rules = ['Suitable for events', 'Pets allowed', 'Smoking allowed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in amenities:\n",
    "    full_df[\"amenities_\"+i] = full_df[\"amenities\"].apply(lambda x: 1 if i in x else 0)\n",
    "full_df[\"amenities_count\"] = sum(full_df[\"amenities_\"+i] for i in amenities)\n",
    "\n",
    "for i in facilities:\n",
    "    full_df[\"facilities_\"+i] = full_df[\"amenities\"].apply(lambda x: 1 if i in x else 0)\n",
    "full_df[\"facilities_count\"] = sum(full_df[\"facilities_\"+i] for i in facilities)\n",
    "\n",
    "for i in house_rules:\n",
    "    full_df[\"house_rules_\"+i] = full_df[\"amenities\"].apply(lambda x: 1 if i in x else 0)\n",
    "full_df[\"house_rules_count\"] = sum(full_df[\"house_rules_\"+i] for i in house_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing Numerical Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"latitude\", \"longitude\", \"property_type\", \"room_type\", \"accommodates\", \"bathrooms\", \"bedrooms\", \"beds\", \"cancellation_policy\", \"amenities_count\", \"facilities_count\", \"house_rules_count\"]:\n",
    "    print(\"STANDARDIZING \"+i.upper()+\"...\")\n",
    "    mean = full_df[i].mean()\n",
    "    std = full_df[i].std()\n",
    "    temp = pd.DataFrame([[mean, std]], columns=[\"mean\", \"std\"], index=[i])\n",
    "    mean_std = mean_std.append(temp)\n",
    "    full_df[i] = (full_df[i] - mean)/std\n",
    "    print(\"--Mean: \", mean)\n",
    "    print(\"--Std: \", std)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = full_df.sample(frac=0.8,random_state=200) #random state is a seed value\n",
    "val_test_df = full_df.drop(train_df.index)\n",
    "val_df = val_test_df.sample(frac=0.5,random_state=200) #random state is a seed value\n",
    "test_df = val_test_df.drop(val_df.index)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"/../split_datasets/train.csv\", index=False)\n",
    "val_df.to_csv(\"/../split_datasets/val.csv\", index=False)\n",
    "test_df.to_csv(\"/../split_datasets/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total # of Samples Remaining:\\t\", len(full_df))\n",
    "print(\"Number of Samples Removed:\\t\", initial_samples - len(full_df))\n",
    "print(\"% of Samples Removed:\\t\\t\", (initial_samples - len(full_df))/initial_samples*100.0)\n",
    "print(\"Number of Train Samples:\\t\", len(train_df))\n",
    "print(\"Number of Val Samples:\\t\\t\", len(val_df))\n",
    "print(\"Number of Test Samples:\\t\\t\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std.to_csv(\"mean_std.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = full_df.corrwith(full_df[\"price\"]).drop([\"id\", \"price\"])\n",
    "corr.plot.bar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
