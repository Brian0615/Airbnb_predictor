{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Req'd Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Getting File Names & Saving csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all the file_names in a given directory\n",
    "def get_file_names(folder):\n",
    "    #Listing entries present in given folder\n",
    "    entries = os.listdir(folder)\n",
    "    for i in entries:\n",
    "        if 'csv' not in i:\n",
    "            entries.remove(i)\n",
    "    return sorted(entries, reverse=True)\n",
    "\n",
    "#Saving the file\n",
    "def save_file(root, name_of_file,my_dataframe):\n",
    "    #Test if save directory exists\n",
    "    try:\n",
    "        my_dataframe.to_csv(root+'processed_data/'+ name_of_file)\n",
    "    #Otherwise make the directory and then save\n",
    "    except:\n",
    "        os.mkdir(root+'processed_data')\n",
    "        my_dataframe.to_csv(root+'processed_data/'+ name_of_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Initialization of File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(filepath):\n",
    "    df = pd.read_csv(filepath, \n",
    "                     usecols = ['id','last_scraped', 'host_is_superhost', \n",
    "                            'neighbourhood_cleansed', 'property_type',\n",
    "                           'room_type','accommodates','bathrooms',\n",
    "                           'bedrooms','beds','amenities', 'price',\n",
    "                           'minimum_nights','maximum_nights',\n",
    "                            'instant_bookable','cancellation_policy'])\n",
    "    df[\"last_scraped\"] = pd.to_datetime(df[\"last_scraped\"])\n",
    "    df[\"price\"] = df[\"price\"].apply(lambda x: x.replace('$','').replace(',', '').replace('.00', '')).astype(\"int\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Removing Missing Data and Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to remove missing data\n",
    "def missing_data(my_dataframe):\n",
    "    #computing number of total rows\n",
    "    total_rows = my_dataframe.shape[0]\n",
    "    #Dropping rows if empty cells are present in any of the given rows\n",
    "    my_dataframe = my_dataframe.dropna(subset = ['id','last_scraped', 'host_is_superhost', \n",
    "                            'neighbourhood_cleansed', 'property_type',\n",
    "                           'room_type','accommodates','bathrooms',\n",
    "                           'bedrooms','beds','amenities', 'price',\n",
    "                           'minimum_nights','maximum_nights',\n",
    "                            'instant_bookable','cancellation_policy'])\n",
    "    #Computing number of rows left after removing rows for error checking\n",
    "    total_rows_after = my_dataframe.shape[0]\n",
    "    \n",
    "    #Printing\n",
    "    print('total rows before missing data removal:', total_rows)\n",
    "    print('total rows after missing data removal:', total_rows_after)\n",
    "    \n",
    "    return my_dataframe\n",
    "\n",
    "\n",
    "def remove_outlier(my_dataframe):\n",
    "    \n",
    "    #Plotting a box and whisker plot for data visualization\n",
    "    sns.boxplot(x=my_dataframe['price'])\n",
    "    #Computing the quantiles of the box and whisker plot\n",
    "    quantiles = my_dataframe['price'].quantile([0.0001, 0.01,0.25,0.5,0.75,0.95,0.99])\n",
    "    \n",
    "    #computing number of total rows prior to removing outliers\n",
    "    total_rows = my_dataframe.shape[0]\n",
    "    print('Number of rows before outlier removal',total_rows)\n",
    "    \n",
    "    #Adjusting data based on quantile information\n",
    "    my_new_dataframe = my_dataframe[(my_dataframe['price'] < quantiles.loc[0.99]) & (my_dataframe['price'] > quantiles.loc[0.01])]\n",
    "    quantiles = my_new_dataframe['price'].quantile([0.0001, 0.01,0.25,0.5,0.75,0.95,0.99])\n",
    "    \n",
    "    #computing new number of total rows\n",
    "    total_rows = my_new_dataframe.shape[0]\n",
    "    \n",
    "    print('Number of rows after outlier removal',total_rows)\n",
    "\n",
    "    return my_new_dataframe\n",
    "\n",
    "#Function for normalizing data \n",
    "def nomarlize_price(my_dataframe):\n",
    "    my_dataframe['price'] = (my_dataframe['price'] - \n",
    "                             my_dataframe['price'].min())/(my_dataframe['price'].max() - \n",
    "                                                         my_dataframe['price'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Mapping Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map neighbourhood names to modified MLS district codes\n",
    "def map_neighbourhoods(data, n_data):\n",
    "    \n",
    "    district = dict(zip(n_data[\"neighbourhood\"].tolist(), n_data[\"district\"].tolist()))\n",
    "    district_group = dict(zip(n_data[\"neighbourhood\"].tolist(), n_data[\"district_group\"].tolist()))\n",
    "    district_number = dict(zip(n_data[\"neighbourhood\"].tolist(), n_data[\"district_number\"].tolist()))\n",
    "\n",
    "    \n",
    "    data[\"district_group\"] = data[\"neighbourhood_cleansed\"].map(district_group)\n",
    "    data[\"district_number\"] = data[\"neighbourhood_cleansed\"].map(district_number)\n",
    "    data[\"district\"] = data[\"district_group\"]*15+data[\"district_number\"]\n",
    "    return data\n",
    "\n",
    "# Convert categorical data (e.g. host_is_superhost) into numerical codes\n",
    "def cat_to_code(data, root, categories):\n",
    "    category_codes = {}\n",
    "    \n",
    "    for i in categories:\n",
    "        name = data[i].name\n",
    "        category_codes[name] = data[i].astype(\"category\").cat.categories # save list of categories\n",
    "        data[name+\"_codes\"] = data[i].astype(\"category\").cat.codes # convert to code\n",
    "    \n",
    "    for i in category_codes:\n",
    "        df = pd.DataFrame()\n",
    "        df[i] = category_codes[i]\n",
    "        df.to_csv(root+r\"category_codes/\"+i+\".csv\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Filter out categories with a small percentage (<5% of data)\n",
    "def filter_categorical(data, properties, can_policy):\n",
    "    num_samples = data.shape[0]\n",
    "    data = data[data.property_type.isin(properties)]\n",
    "    num_samples2 = data.shape[0]\n",
    "    data = data[data.cancellation_policy.isin(can_policy)]\n",
    "    num_samples3 = data.shape[0]\n",
    "    removed = {\"properties\": num_samples-num_samples2,\n",
    "               \"can_policy\": num_samples2-num_samples3}\n",
    "    print(\"Number removed:\")\n",
    "    print(removed)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Filtering of Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amenityRemoval(df, toKeep):\n",
    "    toKeep = ['TV', 'Internet', 'Wifi', 'Air conditioning', 'Kitchen', 'Indoor fireplace', 'Heating', \n",
    "          'Family/kid friendly', 'Washer', 'Dryer', 'Smoke detector', 'First aid kit', 'Fire extinguisher', \n",
    "          'Essentials', 'Shampoo', 'Cable TV', 'Pool', 'Free parking on premises', 'Doorman', 'Gym', 'Elevator', \n",
    "          'Buzzer/wireless intercom', 'Free street parking', 'Carbon monoxide detector', 'Lock on bedroom door', \n",
    "          '24-hour check-in', 'Hangers', 'Hair dryer', 'Iron', 'Laptop friendly workspace',  \n",
    "          'Self check-in', 'Keypad', 'Private entrance', 'Hot water', 'Bed linens', 'Extra pillows and blankets', \n",
    "          'Microwave', 'Coffee maker', 'Refrigerator', 'Dishes and silverware', 'Cooking basics', 'Oven', 'Stove', \n",
    "          'Long term stays allowed', 'No stairs or steps to enter', 'Wheelchair accessible', 'Pets allowed', \n",
    "          'Dishwasher', 'Single level home', 'Patio or balcony', 'Luggage dropoff allowed', \n",
    "          'Paid parking on premises', 'Host greets you', 'Lockbox', 'Garden or backyard', \n",
    "          'Paid parking off premises', 'Private living room', 'Breakfast', 'Hot tub', \n",
    "          'Wide hallways', 'Safety card', 'Bathtub', 'BBQ grill', 'Room-darkening shades', \n",
    "          'Well-lit path to entrance', 'Lake access', 'Ethernet connection', 'Wide entrance for guests', \n",
    "          'Flat path to guest entrance', 'Extra space around bed', 'Wide entrance']\n",
    "    amen = []\n",
    "    \n",
    "    for p in range(len(df)):\n",
    "        amen = df[\"amenities\"][p]\n",
    "        amen = amen[1:len(amen)-1]\n",
    "        amen = str(amen)\n",
    "        amen = amen.replace(\"\\\"\", \"\")\n",
    "        amen = amen.split(\",\")\n",
    "\n",
    "    for i in amen:\n",
    "        if i not in toKeep:\n",
    "            amen.remove(i)   \n",
    "\n",
    "    for j in toKeep:\n",
    "        df[j] = df[\"amenities\"].apply(lambda x: j in x).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  19_08_08_listings.csv\n",
      "--Start # of Samples: 21617\n",
      "total rows before missing data removal: 21617\n",
      "total rows after missing data removal: 21580\n",
      "Number of rows before outlier removal 21580\n",
      "Number of rows after outlier removal 21113\n",
      "Number removed:\n",
      "{'properties': 1122, 'can_policy': 67}\n",
      "--End # of Samples: 19924\n",
      "--Total # of Samples Removed 1693\n",
      "--Accumulated # of Samples: 19924\n",
      "Processing:  19_07_08_listings.csv\n",
      "--Start # of Samples: 21312\n",
      "total rows before missing data removal: 21312\n",
      "total rows after missing data removal: 21265\n",
      "Number of rows before outlier removal 21265\n",
      "Number of rows after outlier removal 20800\n",
      "Number removed:\n",
      "{'properties': 1134, 'can_policy': 29}\n",
      "--End # of Samples: 19637\n",
      "--Total # of Samples Removed 1675\n",
      "--Accumulated # of Samples: 39561\n",
      "Processing:  19_06_04_listings.csv\n",
      "--Start # of Samples: 20769\n",
      "total rows before missing data removal: 20769\n",
      "total rows after missing data removal: 20724\n",
      "Number of rows before outlier removal 20724\n",
      "Number of rows after outlier removal 20264\n",
      "Number removed:\n",
      "{'properties': 1131, 'can_policy': 31}\n",
      "--End # of Samples: 19102\n",
      "--Total # of Samples Removed 1667\n",
      "--Accumulated # of Samples: 58663\n",
      "Processing:  19_05_06_listings.csv\n",
      "--Start # of Samples: 20303\n",
      "total rows before missing data removal: 20303\n",
      "total rows after missing data removal: 20244\n",
      "Number of rows before outlier removal 20244\n",
      "Number of rows after outlier removal 19733\n",
      "Number removed:\n",
      "{'properties': 1129, 'can_policy': 30}\n",
      "--End # of Samples: 18574\n",
      "--Total # of Samples Removed 1729\n",
      "--Accumulated # of Samples: 77237\n",
      "Processing:  19_04_08_listings.csv\n",
      "--Start # of Samples: 20143\n",
      "total rows before missing data removal: 20143\n",
      "total rows after missing data removal: 20094\n",
      "Number of rows before outlier removal 20094\n",
      "Number of rows after outlier removal 19577\n",
      "Number removed:\n",
      "{'properties': 1126, 'can_policy': 29}\n",
      "--End # of Samples: 18422\n",
      "--Total # of Samples Removed 1721\n",
      "--Accumulated # of Samples: 95659\n",
      "Processing:  19_03_07_listings.csv\n",
      "--Start # of Samples: 20036\n",
      "total rows before missing data removal: 20036\n",
      "total rows after missing data removal: 19990\n",
      "Number of rows before outlier removal 19990\n",
      "Number of rows after outlier removal 19468\n",
      "Number removed:\n",
      "{'properties': 1142, 'can_policy': 27}\n",
      "--End # of Samples: 18299\n",
      "--Total # of Samples Removed 1737\n",
      "--Accumulated # of Samples: 113958\n",
      "Processing:  19_02_04_listings.csv\n",
      "--Start # of Samples: 19885\n",
      "total rows before missing data removal: 19885\n",
      "total rows after missing data removal: 19846\n",
      "Number of rows before outlier removal 19846\n",
      "Number of rows after outlier removal 19364\n",
      "Number removed:\n",
      "{'properties': 1141, 'can_policy': 28}\n",
      "--End # of Samples: 18195\n",
      "--Total # of Samples Removed 1690\n",
      "--Accumulated # of Samples: 132153\n",
      "Processing:  19_01_13_listings.csv\n",
      "--Start # of Samples: 19653\n",
      "total rows before missing data removal: 19653\n",
      "total rows after missing data removal: 19615\n",
      "Number of rows before outlier removal 19615\n",
      "Number of rows after outlier removal 19159\n",
      "Number removed:\n",
      "{'properties': 1134, 'can_policy': 28}\n",
      "--End # of Samples: 17997\n",
      "--Total # of Samples Removed 1656\n",
      "--Accumulated # of Samples: 150150\n",
      "Processing:  18_12_06_listings.csv\n",
      "--Start # of Samples: 19255\n",
      "total rows before missing data removal: 19255\n",
      "total rows after missing data removal: 19219\n",
      "Number of rows before outlier removal 19219\n",
      "Number of rows after outlier removal 18766\n",
      "Number removed:\n",
      "{'properties': 1056, 'can_policy': 29}\n",
      "--End # of Samples: 17681\n",
      "--Total # of Samples Removed 1574\n",
      "--Accumulated # of Samples: 167831\n",
      "Processing:  18_11_04_listings.csv\n",
      "--Start # of Samples: 18509\n",
      "total rows before missing data removal: 18509\n",
      "total rows after missing data removal: 18470\n",
      "Number of rows before outlier removal 18470\n",
      "Number of rows after outlier removal 18044\n",
      "Number removed:\n",
      "{'properties': 1029, 'can_policy': 29}\n",
      "--End # of Samples: 16986\n",
      "--Total # of Samples Removed 1523\n",
      "--Accumulated # of Samples: 184817\n",
      "Processing:  18_10_06_listings.csv\n",
      "--Start # of Samples: 17343\n",
      "total rows before missing data removal: 17343\n",
      "total rows after missing data removal: 17258\n",
      "Number of rows before outlier removal 17258\n",
      "Number of rows after outlier removal 16875\n",
      "Number removed:\n",
      "{'properties': 990, 'can_policy': 27}\n",
      "--End # of Samples: 15858\n",
      "--Total # of Samples Removed 1485\n",
      "--Accumulated # of Samples: 200675\n",
      "Processing:  18_09_08_listings.csv\n",
      "--Start # of Samples: 17682\n",
      "total rows before missing data removal: 17682\n",
      "total rows after missing data removal: 17643\n",
      "Number of rows before outlier removal 17643\n",
      "Number of rows after outlier removal 17248\n",
      "Number removed:\n",
      "{'properties': 973, 'can_policy': 25}\n",
      "--End # of Samples: 16250\n",
      "--Total # of Samples Removed 1432\n",
      "--Accumulated # of Samples: 216925\n",
      "Processing:  18_08_08_listings.csv\n",
      "--Start # of Samples: 17542\n",
      "total rows before missing data removal: 17542\n",
      "total rows after missing data removal: 17512\n",
      "Number of rows before outlier removal 17512\n",
      "Number of rows after outlier removal 17111\n",
      "Number removed:\n",
      "{'properties': 980, 'can_policy': 25}\n",
      "--End # of Samples: 16106\n",
      "--Total # of Samples Removed 1436\n",
      "--Accumulated # of Samples: 233031\n",
      "Processing:  18_07_06_listings.csv\n",
      "--Start # of Samples: 16570\n",
      "total rows before missing data removal: 16570\n",
      "total rows after missing data removal: 16521\n",
      "Number of rows before outlier removal 16521\n",
      "Number of rows after outlier removal 16136\n",
      "Number removed:\n",
      "{'properties': 945, 'can_policy': 24}\n",
      "--End # of Samples: 15167\n",
      "--Total # of Samples Removed 1403\n",
      "--Accumulated # of Samples: 248198\n",
      "Processing:  18_05_11_listings.csv\n",
      "--Start # of Samples: 15834\n",
      "total rows before missing data removal: 15834\n",
      "total rows after missing data removal: 15744\n",
      "Number of rows before outlier removal 15744\n",
      "Number of rows after outlier removal 15313\n",
      "Number removed:\n",
      "{'properties': 924, 'can_policy': 29}\n",
      "--End # of Samples: 14360\n",
      "--Total # of Samples Removed 1474\n",
      "--Accumulated # of Samples: 262558\n",
      "Processing:  18_04_09_listings.csv\n",
      "--Start # of Samples: 16070\n",
      "total rows before missing data removal: 16070\n",
      "total rows after missing data removal: 16023\n",
      "Number of rows before outlier removal 16023\n",
      "Number of rows after outlier removal 15541\n",
      "Number removed:\n",
      "{'properties': 995, 'can_policy': 5484}\n",
      "--End # of Samples: 9062\n",
      "--Total # of Samples Removed 7008\n",
      "--Accumulated # of Samples: 271620\n",
      "===========================================\n",
      "Data Processing Complete\n",
      "--Total # of Samples Processed:  302523\n",
      "--Total # of Samples Kept:  271620 (89.7849089160163%)\n",
      "--Total # of Samples Removed:  30903 (10.215091083983697%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get list of filenames\n",
    "root = '../'\n",
    "\n",
    "# Categories to convert to code\n",
    "categories = [\"host_is_superhost\", \"property_type\", \"room_type\", \"instant_bookable\", \"cancellation_policy\"]\n",
    "\n",
    "#Properties and cancellation policies to filter\n",
    "properties = [\"Apartment\", \"Condominium\", \"House\", \"Townhouse\", \"Guest suite\", \"Bungalow\"]\n",
    "can_policy = [\"flexible\", \"moderate\", \"strict_14_with_grace_period\"]\n",
    "\n",
    "#mapping for neighbourhoods\n",
    "n_data = pd.read_csv(root+'category_codes/neighbourhoods.csv')\n",
    "\n",
    "#List of Amenities to Keep\n",
    "amenToKeep = ['TV', 'Internet', 'Wifi', 'Air conditioning', 'Kitchen', 'Indoor fireplace', 'Heating', \n",
    "          'Family/kid friendly', 'Washer', 'Dryer', 'Smoke detector', 'First aid kit', 'Fire extinguisher', \n",
    "          'Essentials', 'Shampoo', 'Cable TV', 'Pool', 'Free parking on premises', 'Doorman', 'Gym', 'Elevator', \n",
    "          'Buzzer/wireless intercom', 'Free street parking', 'Carbon monoxide detector', 'Lock on bedroom door', \n",
    "          '24-hour check-in', 'Hangers', 'Hair dryer', 'Iron', 'Laptop friendly workspace',  \n",
    "          'Self check-in', 'Keypad', 'Private entrance', 'Hot water', 'Bed linens', 'Extra pillows and blankets', \n",
    "          'Microwave', 'Coffee maker', 'Refrigerator', 'Dishes and silverware', 'Cooking basics', 'Oven', 'Stove', \n",
    "          'Long term stays allowed', 'No stairs or steps to enter', 'Wheelchair accessible', 'Pets allowed', \n",
    "          'Dishwasher', 'Single level home', 'Patio or balcony', 'Luggage dropoff allowed', \n",
    "          'Paid parking on premises', 'Host greets you', 'Lockbox', 'Garden or backyard', \n",
    "          'Paid parking off premises', 'Private living room', 'Breakfast', 'Hot tub', \n",
    "          'Wide hallways', 'Safety card', 'Bathtub', 'BBQ grill', 'Room-darkening shades', \n",
    "          'Well-lit path to entrance', 'Lake access', 'Ethernet connection', 'Wide entrance for guests', \n",
    "          'Flat path to guest entrance', 'Extra space around bed', 'Wide entrance']\n",
    "\n",
    "#obtain list of files\n",
    "name = get_file_names(root+'full_dataset')\n",
    "accum_kept = 0\n",
    "accum_removed = 0\n",
    "for i in name:\n",
    "    print(\"Processing: \", i)\n",
    "    filepath = root+'full_dataset/'+i\n",
    "    df = initialization(filepath)\n",
    "    start_len = len(df)\n",
    "    print(\"--Start # of Samples:\", start_len)\n",
    "    \n",
    "    df = missing_data(df)\n",
    "    df = remove_outlier(df)\n",
    "    df = amenityRemoval(df, amenToKeep)\n",
    "    df = pd.get_dummies(df)\n",
    "    df = nomarlize_price(df)\n",
    "    #df = map_neighbourhoods(df, n_data)\n",
    "    #df = cat_to_code(df, root, categories)\n",
    "    #df = filter_categorical(df, properties, can_policy)\n",
    "    df = df.reset_index(drop=True)\n",
    "    end_len = len(df)\n",
    "    print(\"--End # of Samples:\", end_len)\n",
    "    print(\"--Total # of Samples Removed\", start_len-end_len)\n",
    "    save_file(root, i, df)\n",
    "    accum_kept += end_len\n",
    "    accum_removed += start_len-end_len\n",
    "    print(\"--Accumulated # of Samples:\", accum_kept)\n",
    "\n",
    "print(\"===========================================\")\n",
    "print(\"Data Processing Complete\")\n",
    "print(\"--Total # of Samples Processed: \", accum_kept+accum_removed)\n",
    "print(\"--Total # of Samples Kept: \", accum_kept, \"(\"+str(accum_kept/(accum_kept+accum_removed)*100)+\"%)\")\n",
    "print(\"--Total # of Samples Removed: \", accum_removed, \"(\"+str(accum_removed/(accum_kept+accum_removed)*100)+\"%)\")\n",
    "    \n",
    "#save_file(name[1],df)\n",
    "#df = missing_data(df)\n",
    "#df = remove_outlier(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18_04_09_listings.csv',\n",
       " '18_05_11_listings.csv',\n",
       " '18_07_06_listings.csv',\n",
       " '18_08_08_listings.csv',\n",
       " '18_09_08_listings.csv',\n",
       " '18_10_06_listings.csv',\n",
       " '18_11_04_listings.csv',\n",
       " '18_12_06_listings.csv',\n",
       " '19_01_13_listings.csv',\n",
       " '19_02_04_listings.csv',\n",
       " '19_03_07_listings.csv',\n",
       " '19_04_08_listings.csv',\n",
       " '19_05_06_listings.csv',\n",
       " '19_06_04_listings.csv',\n",
       " '19_07_08_listings.csv',\n",
       " '19_08_08_listings.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../processed_data/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root+\"processed_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
