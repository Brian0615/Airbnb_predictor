{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(folder):\n",
    "    #Listing entries present in given folder\n",
    "    entries = os.listdir(folder)\n",
    "    for i in entries:\n",
    "        if 'csv' not in i:\n",
    "            entries.remove(i)\n",
    "    return sorted(entries, reverse=True)[0:12]\n",
    "\n",
    "train_path = \"../data/train/\"\n",
    "test_path = \"../data/test/\"\n",
    "val_path = \"../data/validation/\"\n",
    "\n",
    "train_files = get_file_names(train_path)\n",
    "test_files = get_file_names(test_path)\n",
    "val_files = get_file_names(val_path)\n",
    "\n",
    "frames = []\n",
    "for i in train_files:\n",
    "    frames.append(pd.read_csv(train_path+i))\n",
    "train_df = pd.concat(frames)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "frames = []\n",
    "for i in test_files:\n",
    "    frames.append(pd.read_csv(test_path+i))\n",
    "test_df = pd.concat(frames)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "frames = []\n",
    "for i in val_files:\n",
    "    frames.append(pd.read_csv(val_path+i))\n",
    "val_df = pd.concat(frames)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class airbnb_dataset (Dataset):\n",
    "    def __init__(self, df, purpose):\n",
    "        self.df = df\n",
    "        self.price = self.df[\"price\"]\n",
    "        self.df = self.df.drop(columns=\"price\")\n",
    "        self.purpose = purpose\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Returns specific sample as a dict\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        sample = torch.tensor(self.df.iloc[index]).float()\n",
    "        label = torch.tensor([self.price.iloc[index]]).float()\n",
    "        return {\"sample\": sample, \"label\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = airbnb_dataset(train_df, \"train\")\n",
    "test_ds = airbnb_dataset(test_df, \"test\")\n",
    "val_ds = airbnb_dataset(val_df, \"test\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=1000, num_workers=4)\n",
    "test_loader = DataLoader(test_ds, batch_size=1000, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=1000, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class airbnb_net (nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(airbnb_net, self).__init__()\n",
    "        self.layer1 = nn.Linear(29, 100)\n",
    "        self.layer2 = nn.Linear(100, 20)\n",
    "        self.layer3 = nn.Linear(20, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, val_loader):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.000001, momentum = 0.9)\n",
    "    \n",
    "    print(\"Starting Training...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(200):\n",
    "        epoch_loss = 0\n",
    "        epoch_time = time.time()\n",
    "        batch_loss = 0\n",
    "        batch_time = time.time()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            sample = data[\"sample\"]\n",
    "            label = data[\"label\"]\n",
    "            output = net(sample)\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss += loss\n",
    "            epoch_loss += loss\n",
    "            break\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                batch_loss = batch_loss/10\n",
    "                print(\"---[ITER %d] loss: %.3f  time: %.3f\" % (i, batch_loss, time.time()-batch_time))\n",
    "                batch_loss = 0\n",
    "                batch_time = time.time()\n",
    "        epoch_loss /= len(train_loader)\n",
    "        \n",
    "        print(\"[EPOCH %d] loss: %.3f  time: %.3f\" % (epoch+1, epoch_loss, time.time()-epoch_time))\n",
    "    \n",
    "    print(\"=========================================\")\n",
    "    print(\"Training Completed...\")\n",
    "    print(\"[FINAL] loss: %.3f  time: %.3f\" % (epoch_loss, time.time()-start_time()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = airbnb_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "[EPOCH 1] loss: 251.529  time: 3.160\n",
      "[EPOCH 2] loss: 251.458  time: 3.846\n",
      "[EPOCH 3] loss: 251.324  time: 2.911\n",
      "[EPOCH 4] loss: 251.136  time: 3.433\n",
      "[EPOCH 5] loss: 250.905  time: 3.160\n",
      "[EPOCH 6] loss: 250.643  time: 2.979\n",
      "[EPOCH 7] loss: 250.359  time: 2.922\n",
      "[EPOCH 8] loss: 250.061  time: 3.503\n",
      "[EPOCH 9] loss: 249.756  time: 3.191\n",
      "[EPOCH 10] loss: 249.462  time: 4.277\n",
      "[EPOCH 11] loss: 249.202  time: 2.958\n",
      "[EPOCH 12] loss: 248.940  time: 2.718\n",
      "[EPOCH 13] loss: 248.664  time: 3.093\n",
      "[EPOCH 14] loss: 248.371  time: 2.814\n",
      "[EPOCH 15] loss: 248.058  time: 3.454\n",
      "[EPOCH 16] loss: 247.722  time: 3.636\n",
      "[EPOCH 17] loss: 247.362  time: 3.447\n",
      "[EPOCH 18] loss: 246.974  time: 2.958\n",
      "[EPOCH 19] loss: 246.557  time: 2.833\n",
      "[EPOCH 20] loss: 246.107  time: 3.153\n",
      "[EPOCH 21] loss: 245.621  time: 3.633\n",
      "[EPOCH 22] loss: 245.095  time: 3.242\n",
      "[EPOCH 23] loss: 244.526  time: 3.073\n",
      "[EPOCH 24] loss: 243.909  time: 3.181\n",
      "[EPOCH 25] loss: 243.239  time: 3.103\n",
      "[EPOCH 26] loss: 242.509  time: 2.846\n",
      "[EPOCH 27] loss: 241.715  time: 2.907\n",
      "[EPOCH 28] loss: 240.849  time: 3.239\n",
      "[EPOCH 29] loss: 239.903  time: 2.575\n",
      "[EPOCH 30] loss: 238.870  time: 4.035\n",
      "[EPOCH 31] loss: 237.739  time: 4.976\n",
      "[EPOCH 32] loss: 236.501  time: 2.846\n",
      "[EPOCH 33] loss: 235.145  time: 3.029\n",
      "[EPOCH 34] loss: 233.659  time: 2.733\n",
      "[EPOCH 35] loss: 232.030  time: 3.180\n",
      "[EPOCH 36] loss: 230.244  time: 3.102\n",
      "[EPOCH 37] loss: 228.286  time: 4.024\n",
      "[EPOCH 38] loss: 226.141  time: 5.002\n",
      "[EPOCH 39] loss: 223.792  time: 2.892\n",
      "[EPOCH 40] loss: 221.224  time: 2.800\n",
      "[EPOCH 41] loss: 218.421  time: 3.164\n",
      "[EPOCH 42] loss: 215.371  time: 2.786\n",
      "[EPOCH 43] loss: 212.061  time: 3.183\n",
      "[EPOCH 44] loss: 208.485  time: 2.897\n",
      "[EPOCH 45] loss: 204.643  time: 3.061\n",
      "[EPOCH 46] loss: 200.544  time: 3.131\n",
      "[EPOCH 47] loss: 196.207  time: 2.308\n",
      "[EPOCH 48] loss: 191.669  time: 4.164\n",
      "[EPOCH 49] loss: 186.984  time: 3.042\n",
      "[EPOCH 50] loss: 182.226  time: 2.783\n",
      "[EPOCH 51] loss: 177.495  time: 2.912\n",
      "[EPOCH 52] loss: 172.913  time: 2.530\n",
      "[EPOCH 53] loss: 168.622  time: 3.021\n",
      "[EPOCH 54] loss: 164.774  time: 2.844\n",
      "[EPOCH 55] loss: 161.521  time: 2.687\n",
      "[EPOCH 56] loss: 158.992  time: 2.778\n",
      "[EPOCH 57] loss: 157.269  time: 2.999\n",
      "[EPOCH 58] loss: 156.367  time: 2.767\n",
      "[EPOCH 59] loss: 156.218  time: 3.127\n",
      "[EPOCH 60] loss: 156.667  time: 3.261\n",
      "[EPOCH 61] loss: 157.486  time: 3.331\n",
      "[EPOCH 62] loss: 158.410  time: 3.298\n",
      "[EPOCH 63] loss: 159.185  time: 2.797\n",
      "[EPOCH 64] loss: 159.607  time: 2.632\n",
      "[EPOCH 65] loss: 159.566  time: 3.235\n",
      "[EPOCH 66] loss: 159.048  time: 2.892\n",
      "[EPOCH 67] loss: 158.125  time: 3.382\n",
      "[EPOCH 68] loss: 156.926  time: 2.910\n",
      "[EPOCH 69] loss: 155.603  time: 2.780\n",
      "[EPOCH 70] loss: 154.293  time: 2.974\n",
      "[EPOCH 71] loss: 153.101  time: 2.729\n",
      "[EPOCH 72] loss: 152.089  time: 2.605\n",
      "[EPOCH 73] loss: 151.281  time: 2.720\n",
      "[EPOCH 74] loss: 150.664  time: 3.453\n",
      "[EPOCH 75] loss: 150.207  time: 2.740\n",
      "[EPOCH 76] loss: 149.868  time: 3.186\n",
      "[EPOCH 77] loss: 149.599  time: 2.749\n",
      "[EPOCH 78] loss: 149.360  time: 2.807\n",
      "[EPOCH 79] loss: 149.115  time: 3.055\n",
      "[EPOCH 80] loss: 148.836  time: 3.434\n",
      "[EPOCH 81] loss: 148.509  time: 2.784\n",
      "[EPOCH 82] loss: 148.123  time: 2.941\n",
      "[EPOCH 83] loss: 147.678  time: 2.767\n",
      "[EPOCH 84] loss: 147.179  time: 3.139\n",
      "[EPOCH 85] loss: 146.636  time: 2.985\n",
      "[EPOCH 86] loss: 146.059  time: 3.006\n",
      "[EPOCH 87] loss: 145.463  time: 2.832\n",
      "[EPOCH 88] loss: 144.858  time: 2.626\n",
      "[EPOCH 89] loss: 144.258  time: 3.247\n",
      "[EPOCH 90] loss: 143.669  time: 3.758\n",
      "[EPOCH 91] loss: 143.097  time: 2.850\n",
      "[EPOCH 92] loss: 142.543  time: 2.619\n",
      "[EPOCH 93] loss: 142.007  time: 2.846\n",
      "[EPOCH 94] loss: 141.485  time: 2.734\n",
      "[EPOCH 95] loss: 140.968  time: 2.953\n",
      "[EPOCH 96] loss: 140.452  time: 3.803\n",
      "[EPOCH 97] loss: 139.928  time: 3.615\n",
      "[EPOCH 98] loss: 139.390  time: 2.747\n",
      "[EPOCH 99] loss: 138.834  time: 2.636\n",
      "[EPOCH 100] loss: 138.257  time: 2.701\n",
      "[EPOCH 101] loss: 137.657  time: 3.103\n",
      "[EPOCH 102] loss: 137.036  time: 2.619\n",
      "[EPOCH 103] loss: 136.395  time: 2.874\n",
      "[EPOCH 104] loss: 135.738  time: 3.074\n",
      "[EPOCH 105] loss: 135.067  time: 2.833\n",
      "[EPOCH 106] loss: 134.385  time: 2.446\n",
      "[EPOCH 107] loss: 133.694  time: 2.428\n",
      "[EPOCH 108] loss: 132.993  time: 2.679\n",
      "[EPOCH 109] loss: 132.285  time: 2.763\n",
      "[EPOCH 110] loss: 131.566  time: 3.060\n",
      "[EPOCH 111] loss: 130.837  time: 2.841\n",
      "[EPOCH 112] loss: 130.095  time: 3.274\n",
      "[EPOCH 113] loss: 129.339  time: 2.859\n",
      "[EPOCH 114] loss: 128.564  time: 3.981\n",
      "[EPOCH 115] loss: 127.772  time: 3.039\n",
      "[EPOCH 116] loss: 126.958  time: 3.139\n",
      "[EPOCH 117] loss: 126.124  time: 3.034\n",
      "[EPOCH 118] loss: 125.267  time: 2.968\n",
      "[EPOCH 119] loss: 124.389  time: 3.194\n",
      "[EPOCH 120] loss: 123.487  time: 3.435\n",
      "[EPOCH 121] loss: 122.564  time: 4.010\n",
      "[EPOCH 122] loss: 121.618  time: 4.149\n",
      "[EPOCH 123] loss: 120.651  time: 4.180\n",
      "[EPOCH 124] loss: 119.662  time: 3.668\n",
      "[EPOCH 125] loss: 118.650  time: 7.314\n",
      "[EPOCH 126] loss: 117.618  time: 4.789\n",
      "[EPOCH 127] loss: 116.563  time: 2.863\n",
      "[EPOCH 128] loss: 115.489  time: 3.316\n",
      "[EPOCH 129] loss: 114.394  time: 2.721\n",
      "[EPOCH 130] loss: 113.278  time: 2.838\n",
      "[EPOCH 131] loss: 112.138  time: 2.438\n",
      "[EPOCH 132] loss: 110.975  time: 3.565\n",
      "[EPOCH 133] loss: 109.787  time: 2.876\n",
      "[EPOCH 134] loss: 108.574  time: 3.208\n",
      "[EPOCH 135] loss: 107.336  time: 3.436\n",
      "[EPOCH 136] loss: 106.073  time: 3.596\n",
      "[EPOCH 137] loss: 104.787  time: 2.847\n",
      "[EPOCH 138] loss: 103.480  time: 2.997\n",
      "[EPOCH 139] loss: 102.152  time: 3.763\n",
      "[EPOCH 140] loss: 100.805  time: 5.174\n",
      "[EPOCH 141] loss: 99.439  time: 3.126\n",
      "[EPOCH 142] loss: 98.056  time: 3.676\n",
      "[EPOCH 143] loss: 96.656  time: 3.380\n",
      "[EPOCH 144] loss: 95.242  time: 3.320\n",
      "[EPOCH 145] loss: 93.813  time: 3.332\n",
      "[EPOCH 146] loss: 92.374  time: 2.619\n",
      "[EPOCH 147] loss: 90.926  time: 2.507\n",
      "[EPOCH 148] loss: 89.471  time: 3.269\n",
      "[EPOCH 149] loss: 88.014  time: 2.894\n",
      "[EPOCH 150] loss: 86.556  time: 3.265\n",
      "[EPOCH 151] loss: 85.102  time: 3.155\n",
      "[EPOCH 152] loss: 83.655  time: 3.830\n",
      "[EPOCH 153] loss: 82.218  time: 3.186\n",
      "[EPOCH 154] loss: 80.795  time: 3.074\n",
      "[EPOCH 155] loss: 79.391  time: 3.078\n",
      "[EPOCH 156] loss: 78.010  time: 3.884\n",
      "[EPOCH 157] loss: 76.657  time: 2.584\n",
      "[EPOCH 158] loss: 75.335  time: 2.992\n",
      "[EPOCH 159] loss: 74.048  time: 2.840\n",
      "[EPOCH 160] loss: 72.800  time: 3.179\n",
      "[EPOCH 161] loss: 71.593  time: 2.479\n",
      "[EPOCH 162] loss: 70.432  time: 2.795\n",
      "[EPOCH 163] loss: 69.321  time: 3.273\n",
      "[EPOCH 164] loss: 68.262  time: 2.881\n",
      "[EPOCH 165] loss: 67.256  time: 3.167\n",
      "[EPOCH 166] loss: 66.308  time: 2.598\n",
      "[EPOCH 167] loss: 65.418  time: 3.290\n",
      "[EPOCH 168] loss: 64.588  time: 3.090\n",
      "[EPOCH 169] loss: 63.819  time: 2.502\n",
      "[EPOCH 170] loss: 63.110  time: 2.863\n",
      "[EPOCH 171] loss: 62.462  time: 2.988\n",
      "[EPOCH 172] loss: 61.874  time: 2.751\n",
      "[EPOCH 173] loss: 61.344  time: 3.196\n",
      "[EPOCH 174] loss: 60.871  time: 3.034\n",
      "[EPOCH 175] loss: 60.453  time: 3.183\n",
      "[EPOCH 176] loss: 60.087  time: 3.112\n",
      "[EPOCH 177] loss: 59.770  time: 3.071\n",
      "[EPOCH 178] loss: 59.499  time: 3.443\n",
      "[EPOCH 179] loss: 59.269  time: 3.387\n",
      "[EPOCH 180] loss: 59.077  time: 3.366\n",
      "[EPOCH 181] loss: 58.920  time: 3.267\n",
      "[EPOCH 182] loss: 58.793  time: 3.698\n",
      "[EPOCH 183] loss: 58.692  time: 2.880\n",
      "[EPOCH 184] loss: 58.612  time: 2.908\n",
      "[EPOCH 185] loss: 58.551  time: 2.795\n",
      "[EPOCH 186] loss: 58.506  time: 3.417\n",
      "[EPOCH 187] loss: 58.472  time: 2.918\n",
      "[EPOCH 188] loss: 58.448  time: 3.110\n",
      "[EPOCH 189] loss: 58.430  time: 2.987\n",
      "[EPOCH 190] loss: 58.416  time: 2.841\n",
      "[EPOCH 191] loss: 58.404  time: 2.956\n",
      "[EPOCH 192] loss: 58.393  time: 2.848\n",
      "[EPOCH 193] loss: 58.382  time: 3.031\n",
      "[EPOCH 194] loss: 58.370  time: 2.832\n",
      "[EPOCH 195] loss: 58.355  time: 2.932\n",
      "[EPOCH 196] loss: 58.338  time: 2.694\n",
      "[EPOCH 197] loss: 58.318  time: 3.168\n",
      "[EPOCH 198] loss: 58.297  time: 2.942\n",
      "[EPOCH 199] loss: 58.272  time: 3.114\n",
      "[EPOCH 200] loss: 58.245  time: 3.413\n",
      "=========================================\n",
      "Training Completed...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1d1b4d63f470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-d8e1a2206352>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=========================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Completed...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[FINAL] loss: %.3f  time: %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "train(net, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': tensor([ 1.,  1.,  1.,  1.,  1., 22.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,  1.,\n",
       "          1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.]), 'label': tensor([40.])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: -1.1141770362854004\n",
      "Abs Error: 52.260437908172605\n"
     ]
    }
   ],
   "source": [
    "accum = 0\n",
    "accum1 = 0\n",
    "for i in range(1000):\n",
    "    error = net(train_ds[i][\"sample\"]).item() - train_ds[i][\"label\"].item()\n",
    "    accum += error\n",
    "    accum1 += abs(error)\n",
    "print(\"Error:\", accum/1000)\n",
    "print(\"Abs Error:\", accum1/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181.83848571777344"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(train_ds[4][\"sample\"]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[4][\"label\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
